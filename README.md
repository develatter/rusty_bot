# ğŸ¤– Rusty Bot

<div align="center">

![Rust](https://img.shields.io/badge/rust-%23000000.svg?style=for-the-badge&logo=rust&logoColor=white)
![WebAssembly](https://img.shields.io/badge/WebAssembly-654FF0?style=for-the-badge&logo=webassembly&logoColor=white)
![License](https://img.shields.io/badge/License-GPL%20v3-blue.svg?style=for-the-badge)

*A modern AI chatbot built entirely in Rust with RAG capabilities*

[Features](#-features) â€¢
[Installation](#-installation) â€¢
[Usage](#-usage) â€¢
[Development](#-development)

</div>

---

## ğŸ¯ About

Rusty Bot is an open-source AI chatbot application that demonstrates the power of Rust in building modern web applications. This project serves as both a functional chatbot and an educational resource, showcasing how to integrate large language models with semantic search capabilities using a full-stack Rust approach.

**Academic Context**: This project is part of the Final Degree Project by Alejandro LÃ³pez MartÃ­nez, a student in the 2nd year of Multiplatform Application Development in AlmerÃ­a, Spain.

## âœ¨ Features

### ğŸ§  **AI-Powered Conversations**
- Integration with language models via [Kalosm](https://github.com/floneum/floneum)
- Real-time streaming responses for better user experience
- Conversation history management with reset functionality

### ğŸ” **Semantic Search & RAG**
- Document embedding using BERT models
- Context-aware responses through Retrieval-Augmented Generation (RAG)
- Vector database powered by SurrealDB for semantic search

### ğŸ¨ **Modern Web Interface**
- Responsive design built with Dioxus framework
- Real-time streaming text display
- Markdown support with syntax highlighting
- Dark theme optimized for extended use

### ğŸ›  **Full-Stack Rust Architecture**
- Use of Dioxus as full-stack framework.
- Type-safe communication between client and server
- Zero JavaScript dependencies (except for styling with TailwindCSS)


### Core Components

- **Frontend**: Dioxus-based reactive UI compiled to WebAssembly
- **Backend**: Axum server with Dioxus server functions
- **LLM Engine**: Kalosm integration with Qwen 2.5 7B model
- **Vector Database**: SurrealDB with embedding-based semantic search
- **Context System**: Markdown-based document ingestion with RAG

## ğŸš€ Installation

### Prerequisites

Ensure you have the following installed on your system:

#### 1. Rust Toolchain
```bash
# Install Rust using rustup
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# Follow the on-screen instructions and restart your terminal
# Verify installation
rustc --version
cargo --version
```

#### 2. Dioxus CLI
```bash
# Install Dioxus CLI for development
cargo install dioxus-cli

# Verify installation
dx --version
```

#### 3. System Requirements
- **RAM**: At least 8GB (16GB recommended for LLM operations)
- **Storage**: ~10GB free space for model downloads
- **OS**: Linux, macOS, or Windows with WSL2

### ğŸ”§ Setup

1. **Clone the Repository**
   ```bash
   git clone https://github.com/your-username/rusty_bot.git
   cd rusty_bot
   ```

2. **Create Context Directory (if it doesn't exist)**
   ```bash
   mkdir -p context
   ```

3. **Add Your Documents** (Optional)
   
   Place your Markdown files in the `context/` directory. These will be used for RAG-based responses.

## ğŸ® Usage

```bash
dx serve --platform web --release
```

### ğŸ’¬ Using the Chatbot

1. **Initialize**: The application will automatically download and initialize the language model on first run (this may take several minutes)

2. **Chat**: Type your message in the text area and press Enter or click Send

3. **Context Toggle**: Enable the "Context" toggle to use RAG-based responses with your documents

4. **Reset**: Click the reset button (â†») in the top-left to start a new conversation

## ğŸ›  Development

### Project Structure

```
rusty_bot/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/          # UI components
â”‚   â”‚   â”œâ”€â”€ conversation.rs  # Main chat interface
â”‚   â”‚   â””â”€â”€ message.rs       # Individual message rendering
â”‚   â”œâ”€â”€ model/               # Data models
â”‚   â”‚   â”œâ”€â”€ chat.rs          # Chat message structures
â”‚   â”‚   â””â”€â”€ document.rs      # Document result structures
â”‚   â”œâ”€â”€ server/              # Server-side modules
â”‚   â”‚   â”œâ”€â”€ llm.rs           # Language model integration
â”‚   â”‚   â”œâ”€â”€ embedding.rs     # Text embedding functionality
â”‚   â”‚   â””â”€â”€ database_impl.rs # Database operations
â”‚   â”œâ”€â”€ server_functions/    # Dioxus server functions
â”‚   â””â”€â”€ main.rs              # Application entry point
â”œâ”€â”€ context/                 # Knowledge base documents
â”œâ”€â”€ assets/                  # Static assets
â””â”€â”€ Cargo.toml              # Project dependencies
```

### Adding New Features

1. **Server Functions**: Add new server functions in `src/server_functions/`
2. **UI Components**: Create new components in `src/components/`
3. **Models**: Define data structures in `src/model/`
4. **Context**: Add knowledge base documents to `context/`


## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

## ğŸ“„ License

This project is licensed under the GNU General Public License v3.0 - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Kalosm](https://github.com/floneum/floneum) - For providing excellent Rust LLM integration
- [Dioxus](https://dioxuslabs.com/) - For the amazing full-stack Rust framework
- [SurrealDB](https://surrealdb.com/) - For the powerful multi-model database
- The Rust community for creating such amazing tools and libraries

---

<div align="center">
Made with â¤ï¸ and ğŸ¦€ by Alejandro LÃ³pez MartÃ­nez (develatter)
</div>


